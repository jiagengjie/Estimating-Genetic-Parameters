{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from multiprocessing import Pool\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from functools import partial\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1034, 297)\n",
      "(1034, 346)\n"
     ]
    }
   ],
   "source": [
    "# load whole dataset (measurement + prediction)\n",
    "dfwh = pd.read_csv('./Training_Data_H2.csv') #sorted\n",
    "dfwh = dfwh.drop(['H2_se', 'Disease'], axis=1)\n",
    "\n",
    "# using one hot encoding for the categorical data\n",
    "dfwh = dfwh.iloc[0:1034,] ##Training data are at 0: 1034 rows\n",
    "\n",
    "print dfwh.shape\n",
    "dfwh = pd.get_dummies(dfwh)\n",
    "dfwh = dfwh.drop(['Country_of_cohort_Malaysia', 'Country_of_cohort_India', 'Country_of_cohort_Venezuela', 'Country_of_cohort_Germany', 'Country_of_cohort_Brazil', 'Country_of_cohort_France', 'Country_of_cohort_Poland'], axis=1)\n",
    "print dfwh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1034, 345)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training and testing data\n",
    "feature_wh = dfwh.iloc[:, 1:].values\n",
    "value = dfwh.iloc[:, 0].values\n",
    "\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(feature_wh)\n",
    "feature_scaled = scaler.transform(feature_wh)\n",
    "print feature_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reg_split(regressor, feature_scaled, value, seed, test_size=0.2):\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "        feature_scaled, value, test_size=test_size, random_state=seed)\n",
    "    regressor.fit(Xtrain, Ytrain)\n",
    "    Y_pred = regressor.predict(Xtest)\n",
    "# #     make the code print the feature importance\n",
    "#     if hasattr(regressor, 'feature_importances_'):\n",
    "#         with open('./h2_{}_seed_{}'.format(\n",
    "#             str(regressor.__class__).split('.')[-1].split('\\'')[0], seed), 'w') as f:\n",
    "#             f.write(str(regressor.feature_importances_))\n",
    "#     if hasattr(regressor, 'coef_'):\n",
    "#         with open('./h2_{}_seed_{}'.format(\n",
    "#             str(regressor.__class__).split('.')[-1].split('\\'')[0], seed), 'w') as f:\n",
    "#             f.write(str(regressor.coef_))\n",
    "\n",
    "    return np.corrcoef(Ytest, Y_pred)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_wrapper(seed, regressor):\n",
    "    # gbr\n",
    "    gbr = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=0)\n",
    "    # random forest\n",
    "    rf = RandomForestRegressor(max_depth=25, random_state=0)\n",
    "    # adboosted random forrest\n",
    "    adrf = AdaBoostRegressor(RandomForestRegressor(max_depth=25, random_state=0, n_jobs=-1),\n",
    "                              n_estimators=200, random_state=0)\n",
    "    # boosted quantile\n",
    "    bq = GradientBoostingRegressor(loss='quantile', alpha=0.13,\n",
    "                                    n_estimators=200, max_depth=5,\n",
    "                                    learning_rate=.2, min_samples_leaf=9,\n",
    "                                    min_samples_split=9)\n",
    "    # svr\n",
    "    svr = SVR(kernel='rbf', gamma=0.01, C=10)\n",
    "    # krr\n",
    "    krr = KernelRidge(alpha=0.02, kernel='rbf', gamma=0.1)\n",
    "    # lasso\n",
    "    lasso = linear_model.Lasso(alpha=0.00001)\n",
    "    # huber regression\n",
    "    hr = linear_model.HuberRegressor(epsilon=10)\n",
    "    # ridge\n",
    "    ridge = linear_model.Ridge(alpha=0.1)\n",
    "    reg_dict = {'gbr': gbr, 'rf': rf, 'adrf':adrf, 'bq': bq,\n",
    "                'svr': svr,'lasso':lasso,'krr': krr, 'hr': hr,\n",
    "                'ridge': ridge}\n",
    "    return reg_split(reg_dict[regressor], feature_scaled, value, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repeat_1000(regressor):\n",
    "    p = Pool()\n",
    "    result = np.array(p.map(partial(split_wrapper, regressor=regressor), range(1000)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85917855  0.8764764   0.87379697  0.86301541  0.89673423  0.88277897\n",
      "  0.88029269  0.88399208  0.88547249  0.85037128  0.88478705  0.89842267\n",
      "  0.87860628  0.8790743   0.88703751  0.89874421  0.84887685  0.85572593\n",
      "  0.87670131  0.87861276  0.89265409  0.88474647  0.86062378  0.8805523\n",
      "  0.86450166  0.8701716   0.89098615  0.88909336  0.88492894  0.87265892\n",
      "  0.87285418  0.87003371  0.84189427  0.84833412  0.87098593  0.8632692\n",
      "  0.84719265  0.86138413  0.8613933   0.85620456  0.86331405  0.8653829\n",
      "  0.86771975  0.87684961  0.89454406  0.89394174  0.89112233  0.91003234\n",
      "  0.85912955  0.88340098  0.88116712  0.86875233  0.87740777  0.90542012\n",
      "  0.88687994  0.88601204  0.86684338  0.89522334  0.87834242  0.87951559\n",
      "  0.87927408  0.84024173  0.89083692  0.84256823  0.87278887  0.86094239\n",
      "  0.87103613  0.86230991  0.85512578  0.89890575  0.84999799  0.90134613\n",
      "  0.84190167  0.83812938  0.87269122  0.86579616  0.88059647  0.85220424\n",
      "  0.84230806  0.89877812  0.85227488  0.87385465  0.87046781  0.85471733\n",
      "  0.86866536  0.88782435  0.87489319  0.89109104  0.86651663  0.86804321\n",
      "  0.86919802  0.85977072  0.90085557  0.87867854  0.89139852  0.90305493\n",
      "  0.88177153  0.86382222  0.89362248  0.87815287  0.88622371  0.86851348\n",
      "  0.89053733  0.81359947  0.89449919  0.86695845  0.89053277  0.8839266\n",
      "  0.83325626  0.86958279  0.86317211  0.91953698  0.85027424  0.85513611\n",
      "  0.87473958  0.87196186  0.86404468  0.85032983  0.88003403  0.86508704\n",
      "  0.87806404  0.85987797  0.87336402  0.82977113  0.87476308  0.84350007\n",
      "  0.87656387  0.86775292  0.88641336  0.86127327  0.87203329  0.89579023\n",
      "  0.86576751  0.90167762  0.87214876  0.87955016  0.8837774   0.88577967\n",
      "  0.82954594  0.87158749  0.87280504  0.89059608  0.88809541  0.86879889\n",
      "  0.89229752  0.89811134  0.86816572  0.84486995  0.8286859   0.87303719\n",
      "  0.84940632  0.89245399  0.88251502  0.89844927  0.83769669  0.88640682\n",
      "  0.86916132  0.84579107  0.85710237  0.90252777  0.86526826  0.87402777\n",
      "  0.85420274  0.87108446  0.87429682  0.87167527  0.8902303   0.88075399\n",
      "  0.90210008  0.87856545  0.87741587  0.85789544  0.86925655  0.86318818\n",
      "  0.86569381  0.88445544  0.90376127  0.86026295  0.84113384  0.87083319\n",
      "  0.859734    0.88830144  0.8500966   0.841936    0.86223678  0.8935781\n",
      "  0.87391259  0.88273768  0.88327759  0.8897191   0.85856152  0.83887405\n",
      "  0.87317381  0.87191052  0.86841724  0.85144405  0.89177083  0.87165174\n",
      "  0.90242752  0.87591447  0.86188451  0.82410752  0.87604619  0.85268011\n",
      "  0.87428225  0.87500551  0.86356282  0.90296793  0.86310391  0.86275468\n",
      "  0.89477655  0.86609557  0.89925185  0.85782736  0.86768403  0.87051702\n",
      "  0.87201729  0.86371992  0.86554803  0.88798561  0.88959315  0.84623838\n",
      "  0.85653592  0.90115817  0.86899242  0.87439121  0.84681707  0.89015023\n",
      "  0.87209251  0.8803302   0.84918025  0.88841305  0.89082359  0.86904196\n",
      "  0.84342819  0.86459297  0.86209861  0.87882788  0.87865243  0.89312446\n",
      "  0.84803059  0.86673691  0.87995984  0.85737128  0.88945324  0.86678305\n",
      "  0.85788142  0.89212018  0.88104378  0.88545945  0.89349131  0.85997727\n",
      "  0.87157054  0.88646648  0.86339323  0.83407745  0.87560307  0.86119771\n",
      "  0.85544586  0.875308    0.84245869  0.88756762  0.86060595  0.85671974\n",
      "  0.86115073  0.87487209  0.88415771  0.85948934  0.86165528  0.87901067\n",
      "  0.87239592  0.89462991  0.86540228  0.88589641  0.86134756  0.8663052\n",
      "  0.84102602  0.88500277  0.86597946  0.90437388  0.90764292  0.88162254\n",
      "  0.89878213  0.87852252  0.88843622  0.88766629  0.88118075  0.85923914\n",
      "  0.85918009  0.87341862  0.86707569  0.86804425  0.86626176  0.870316\n",
      "  0.86534409  0.89705289  0.83930723  0.89481194  0.88343211  0.8381788\n",
      "  0.895026    0.88079326  0.85537406  0.86913456  0.88369814  0.90580419\n",
      "  0.88369304  0.88126072  0.85601318  0.83960846  0.88791977  0.89264167\n",
      "  0.8650538   0.87864839  0.84911872  0.90414268  0.85169642  0.8383225\n",
      "  0.88840873  0.87750695  0.88874264  0.86320245  0.86662026  0.85820931\n",
      "  0.85853898  0.87161778  0.87074198  0.86907981  0.87754055  0.86930269\n",
      "  0.86677352  0.85801774  0.90193556  0.86250386  0.86531886  0.86716734\n",
      "  0.85170051  0.91710959  0.85840589  0.88351302  0.87057974  0.88233886\n",
      "  0.88573943  0.88077154  0.86566251  0.86448182  0.87001252  0.82498218\n",
      "  0.8487314   0.85924071  0.88925218  0.87531114  0.86569775  0.82240336\n",
      "  0.85044747  0.85554409  0.8680038   0.87120572  0.89150444  0.86676374\n",
      "  0.90114198  0.89285873  0.86640654  0.88160294  0.87800232  0.87669154\n",
      "  0.86670048  0.84706963  0.86060854  0.88695477  0.8877584   0.83334912\n",
      "  0.84074188  0.87209175  0.87324584  0.86361081  0.85819016  0.87221439\n",
      "  0.88299609  0.87250906  0.87254985  0.91121644  0.86481712  0.81930149\n",
      "  0.87279682  0.84060391  0.88148187  0.88473641  0.86817178  0.87748556\n",
      "  0.86090673  0.87775885  0.86463471  0.87159165  0.89051617  0.84908269\n",
      "  0.86460535  0.86934038  0.87757443  0.86695958  0.8301876   0.90009691\n",
      "  0.87643077  0.90084019  0.87412529  0.86040402  0.82293426  0.84962234\n",
      "  0.89307151  0.87639415  0.83939276  0.85314188  0.8476623   0.89064216\n",
      "  0.84100204  0.86729067  0.88396328  0.87888956  0.85933783  0.87503244\n",
      "  0.87996162  0.84344913  0.88041722  0.89127002  0.87452682  0.89714423\n",
      "  0.87131288  0.86386706  0.92259745  0.87377556  0.82995134  0.86261954\n",
      "  0.8823735   0.88902522  0.86893499  0.87054366  0.8752942   0.8540812\n",
      "  0.86825778  0.85815621  0.87257318  0.86459239  0.85009354  0.87798546\n",
      "  0.89119803  0.89458593  0.86372901  0.86371774  0.88823829  0.85988768\n",
      "  0.84666616  0.89201297  0.89276486  0.88664746  0.86538312  0.89757919\n",
      "  0.89504287  0.89498419  0.8955904   0.87541531  0.84651479  0.85501333\n",
      "  0.83967545  0.85492227  0.87086014  0.85848763  0.86116627  0.88380494\n",
      "  0.86467317  0.84853688  0.8802429   0.8895738   0.86199998  0.87706164\n",
      "  0.88057517  0.88217353  0.85500248  0.86614043  0.86463048  0.84442525\n",
      "  0.89136427  0.88598337  0.88308764  0.86455613  0.8329459   0.87976407\n",
      "  0.87011804  0.87011842  0.89435775  0.85409411  0.85377967  0.86472916\n",
      "  0.89595656  0.87497632  0.87762577  0.83517377  0.89160078  0.87898728\n",
      "  0.87696655  0.88984632  0.90776475  0.87128462  0.89336253  0.86891481\n",
      "  0.87163994  0.85662576  0.88673976  0.85358208  0.86637559  0.87970283\n",
      "  0.86634446  0.87015222  0.87734299  0.8875524   0.89897837  0.84186862\n",
      "  0.88003275  0.8979054   0.81461956  0.86285967  0.83094613  0.85954784\n",
      "  0.8892421   0.84631293  0.87853554  0.87640868  0.84751299  0.86747029\n",
      "  0.86295838  0.88243621  0.90657862  0.87149127  0.86401527  0.88227846\n",
      "  0.88716323  0.87651818  0.88051271  0.87078683  0.8669946   0.83498958\n",
      "  0.86727757  0.86549418  0.86740168  0.88048508  0.86733825  0.88542202\n",
      "  0.8542909   0.9000187   0.8415869   0.86535848  0.85205908  0.86593795\n",
      "  0.83368046  0.88824957  0.88384035  0.86967254  0.87226086  0.89726641\n",
      "  0.87826441  0.87337374  0.8672472   0.8907338   0.86437692  0.8532387\n",
      "  0.88127026  0.83881756  0.87965297  0.86404457  0.8333597   0.85505922\n",
      "  0.84528353  0.87968757  0.8489317   0.86586279  0.82667731  0.87908165\n",
      "  0.87623251  0.90672639  0.8786459   0.85650064  0.89703899  0.85283955\n",
      "  0.87329152  0.87251334  0.892116    0.87153571  0.85649889  0.86056146\n",
      "  0.88435041  0.8711036   0.87357229  0.88092375  0.84495491  0.89189277\n",
      "  0.8657515   0.85092066  0.82837962  0.88551142  0.86343091  0.86769322\n",
      "  0.89688007  0.86399979  0.86580962  0.86766439  0.87179829  0.87246935\n",
      "  0.86626089  0.89185956  0.88232853  0.85314126  0.87491791  0.86984432\n",
      "  0.8841383   0.85467441  0.85886524  0.86233195  0.87866618  0.88265327\n",
      "  0.86136094  0.88660893  0.8142745   0.83708163  0.83291064  0.85092675\n",
      "  0.88803779  0.88081102  0.8969571   0.88271112  0.87507159  0.86965082\n",
      "  0.86493001  0.88802255  0.82577813  0.86038478  0.86874407  0.89425709\n",
      "  0.82304457  0.89226556  0.87775898  0.87172847  0.8635707   0.89332346\n",
      "  0.85764262  0.80009217  0.87055949  0.88433976  0.82071704  0.90324554\n",
      "  0.8802403   0.89045689  0.8617536   0.86649895  0.88963568  0.87182087\n",
      "  0.89400567  0.85943422  0.85818511  0.8709933   0.89103777  0.87710977\n",
      "  0.88899049  0.88183526  0.84102535  0.86557953  0.88220404  0.88134522\n",
      "  0.8740542   0.86832126  0.82195109  0.86440586  0.87419912  0.88969322\n",
      "  0.8725837   0.85520774  0.87903644  0.83663866  0.86837635  0.88380567\n",
      "  0.87988787  0.8577146   0.89682329  0.87434173  0.87611968  0.86505942\n",
      "  0.87564978  0.90572752  0.88528354  0.85507708  0.83223189  0.88919203\n",
      "  0.86201856  0.86796087  0.86002325  0.84720952  0.89214571  0.86852748\n",
      "  0.90042909  0.84216315  0.82310795  0.87372423  0.83550814  0.86589418\n",
      "  0.85918499  0.86215485  0.8446194   0.87340074  0.86868927  0.85798821\n",
      "  0.86229344  0.84485914  0.86089638  0.85257799  0.87156131  0.89151436\n",
      "  0.90065949  0.8612233   0.87800059  0.87722573  0.85356196  0.86755\n",
      "  0.84211449  0.87892515  0.91027587  0.87101812  0.88450861  0.85782512\n",
      "  0.85798843  0.86248113  0.8734675   0.88047247  0.87221682  0.85775977\n",
      "  0.88288703  0.89187113  0.88855254  0.87326986  0.87672853  0.85943193\n",
      "  0.86024074  0.85730268  0.867169    0.87603954  0.85803419  0.88153362\n",
      "  0.87967311  0.86173364  0.87286204  0.89117744  0.85709976  0.90273371\n",
      "  0.84399955  0.86903507  0.8423017   0.85310154  0.87520509  0.8793728\n",
      "  0.8627977   0.87697791  0.84172262  0.87283826  0.85304508  0.87682615\n",
      "  0.87653352  0.88780548  0.89696615  0.88519221  0.88531041  0.90393301\n",
      "  0.890205    0.89926724  0.87623021  0.8567252   0.83022083  0.85743896\n",
      "  0.84170343  0.88179151  0.89282223  0.85365658  0.90100083  0.83537023\n",
      "  0.85862654  0.88661313  0.88992115  0.82756545  0.8699111   0.87031337\n",
      "  0.87784244  0.87742676  0.892127    0.87908412  0.85493473  0.8798891\n",
      "  0.86391556  0.83935148  0.85074794  0.85314005  0.83928437  0.87683209\n",
      "  0.86780937  0.86954624  0.86735863  0.8579142   0.86295157  0.88274013\n",
      "  0.87959851  0.8405019   0.87334761  0.86607649  0.88401238  0.90862768\n",
      "  0.85350095  0.8574088   0.86377134  0.8702487   0.86669254  0.88164832\n",
      "  0.88380634  0.86545506  0.88337111  0.87232831  0.88205861  0.87491172\n",
      "  0.87352848  0.85048158  0.85934046  0.87032636  0.84530077  0.86264295\n",
      "  0.85794566  0.8549196   0.86134304  0.87219749  0.8723931   0.84950002\n",
      "  0.8842294   0.84674535  0.87461891  0.87303805  0.86038247  0.83785909\n",
      "  0.84704668  0.85439186  0.7994099   0.86577317  0.85245991  0.86983402\n",
      "  0.89103153  0.87299426  0.8064084   0.89070206  0.87041729  0.85672654\n",
      "  0.90589577  0.88566655  0.86867585  0.86404568  0.89439214  0.88520973\n",
      "  0.85878734  0.82878851  0.89658951  0.85496989  0.87338942  0.89378155\n",
      "  0.86281234  0.8770818   0.85755386  0.85146554  0.84593259  0.88197426\n",
      "  0.87638946  0.87747031  0.84291954  0.88181322  0.87596022  0.8622053\n",
      "  0.8539493   0.85664679  0.87938291  0.85809122  0.88164888  0.86800095\n",
      "  0.87486924  0.84962176  0.85218723  0.8839234   0.80717846  0.83246203\n",
      "  0.87743763  0.8449387   0.84330864  0.84889093  0.85088902  0.84222215\n",
      "  0.89226375  0.86869769  0.86073613  0.85820393  0.80918646  0.89672768\n",
      "  0.88612156  0.86351656  0.85941296  0.87118974  0.88156467  0.86827856\n",
      "  0.89632618  0.87000727  0.86218056  0.88190699  0.87601135  0.87325191\n",
      "  0.85591888  0.88291143  0.88268961  0.86524627  0.89034602  0.85856593\n",
      "  0.86521666  0.91429525  0.85876188  0.89517519  0.873119    0.89405286\n",
      "  0.8699402   0.85130065  0.87473386  0.85498651  0.85690974  0.87032747\n",
      "  0.85775328  0.84437413  0.85354813  0.87810314  0.86862397  0.86631675\n",
      "  0.88337859  0.88214802  0.84856069  0.868872    0.86565485  0.83990523\n",
      "  0.90116791  0.82052052  0.86924189  0.90325983  0.86500009  0.87754638\n",
      "  0.86909238  0.87356058  0.88726646  0.88869433  0.85159532  0.89344474\n",
      "  0.86868032  0.86529264  0.87573292  0.83952258  0.87039698  0.8970524\n",
      "  0.86409231  0.84075005  0.86851443  0.84952959  0.86253811  0.88040083\n",
      "  0.88370808  0.86155577  0.85191444  0.88276919  0.89094461  0.87045965\n",
      "  0.89246746  0.84805779  0.87365937  0.87757091  0.85955026  0.87196421\n",
      "  0.86483169  0.86523455  0.87919443  0.86646738  0.88891888  0.86983828\n",
      "  0.88268452  0.87920392  0.88161019  0.86948806  0.85022099  0.82775628\n",
      "  0.87179522  0.86206671  0.86024628  0.8294471   0.8780367   0.88708634\n",
      "  0.85898446  0.87950528  0.89104364  0.87256947]\n"
     ]
    }
   ],
   "source": [
    "print(repeat_1000('gbr'))  \n",
    "##pick one name a time from {\"gbr\",\"rf\",\"adrf\",\"bq\",\"svr\",\"lasso\",\"krr\",\"hr\",\"ridge\"}\n",
    "##print correlation coefficients from 1000 repeated runs, based on which we can compute mean value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
