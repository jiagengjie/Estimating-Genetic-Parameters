{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#import tensorflow\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "#import tflearn\n",
    "from sklearn.svm import SVR\n",
    "from multiprocessing import Pool\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5584, 497)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data: woH2b\n",
    "df = pd.read_csv('./Training_Data_Corr.csv')\n",
    "df = df.drop(['corr_SD', 'Disease1', 'Disease2'], axis=1)\n",
    "# using one hot encoding to deal with the categorical data\n",
    "df = pd.get_dummies(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5584, 496)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "feature = df.iloc[:, 1:].values\n",
    "value = df.iloc[:, 0].values\n",
    "\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(feature)\n",
    "feature_scaled = scaler.transform(feature)\n",
    "print feature_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_split(regressor, feature_scaled, value, seed, test_size=0.2):\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "        feature_scaled, value, test_size=test_size, random_state=seed)\n",
    "    regressor.fit(Xtrain, Ytrain)\n",
    "    Y_pred = regressor.predict(Xtest)\n",
    "# #     make the code print the feature importance\n",
    "#     if hasattr(regressor, 'feature_importances_'):\n",
    "#         with open('./corr_{}_seed_{}'.format(\n",
    "#             str(regressor.__class__).split('.')[-1].split('\\'')[0], seed), 'w') as f:\n",
    "#             f.write(str(regressor.feature_importances_))\n",
    "#     if hasattr(regressor, 'coef_'):\n",
    "#         with open('./corr_{}_seed_{}'.format(\n",
    "#             str(regressor.__class__).split('.')[-1].split('\\'')[0], seed), 'w') as f:\n",
    "#             f.write(str(regressor.coef_))\n",
    "#     with open('./corr_{}_seed_{}_real'.format(\n",
    "#             str(regressor.__class__).split('.')[-1].split('\\'')[0], seed), 'w') as f:\n",
    "#             f.write(str(list(Ytest)))\n",
    "#     with open('./corr_{}_seed_{}_pred'.format(\n",
    "#             str(regressor.__class__).split('.')[-1].split('\\'')[0], seed), 'w') as f:\n",
    "#             f.write(str(list(Y_pred)))\n",
    "    return np.corrcoef(Ytest, Y_pred)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_wrapper(seed, regressor):\n",
    "    # gbr\n",
    "    gbr = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=0)\n",
    "    # random forest\n",
    "    rf = RandomForestRegressor(max_depth=25, random_state=0)\n",
    "    # adboosted random forrest\n",
    "    adrf = AdaBoostRegressor(RandomForestRegressor(max_depth=25, random_state=0, n_jobs=-1),\n",
    "                              n_estimators=200, random_state=0)\n",
    "    # boosted quantile\n",
    "    bq = GradientBoostingRegressor(loss='quantile', alpha=0.13,\n",
    "                                    n_estimators=200, max_depth=5,\n",
    "                                    learning_rate=.2, min_samples_leaf=9,\n",
    "                                    min_samples_split=9, random_state=0)\n",
    "    # svr\n",
    "    svr = SVR(kernel='rbf', gamma=0.13, C=10)\n",
    "    # krr\n",
    "    krr = KernelRidge(alpha=0.5, kernel='rbf', gamma=0.1)\n",
    "    # lasso\n",
    "    lasso = linear_model.Lasso(alpha=0.00001)\n",
    "    # huber regression\n",
    "    hr = linear_model.HuberRegressor(epsilon=10)\n",
    "    # ridge\n",
    "    ridge = linear_model.Ridge(alpha=0.1)\n",
    "    reg_dict = {'gbr': gbr, 'rf': rf, 'adrf':adrf, 'bq': bq, 'svr': svr,\n",
    "                   'krr': krr, 'hr': hr, 'ridge': ridge}\n",
    "    return reg_split(reg_dict[regressor], feature_scaled, value, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repeat_1000(regressor):\n",
    "    p = Pool()\n",
    "    result = np.array(p.map(partial(split_wrapper, regressor=regressor), range(1000)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88020002  0.86657003  0.85990833  0.87814604  0.88501171  0.8863638\n",
      "  0.85838448  0.84399948  0.8632723   0.89265895  0.88615922  0.86357819\n",
      "  0.88890976  0.84555033  0.86556103  0.90258385  0.86165723  0.88791671\n",
      "  0.86395912  0.86115074  0.8641894   0.89345659  0.86040079  0.86950166\n",
      "  0.88305749  0.87774187  0.91202547  0.87986616  0.84495147  0.89411804\n",
      "  0.88819761  0.87943409  0.88732982  0.84989517  0.86822123  0.88271033\n",
      "  0.85323641  0.89695257  0.83022067  0.84774173  0.84862432  0.88437987\n",
      "  0.89234936  0.86069045  0.8804212   0.87496727  0.87871225  0.88807752\n",
      "  0.88407792  0.85389324  0.89201828  0.8789199   0.88313466  0.87059078\n",
      "  0.88202284  0.87730122  0.89043752  0.88723369  0.87769148  0.89582398\n",
      "  0.8665267   0.88156284  0.84497097  0.89653309  0.90529052  0.89405755\n",
      "  0.8888627   0.83674596  0.9059838   0.88401048  0.90557887  0.90174616\n",
      "  0.88492941  0.87286611  0.89607441  0.87220034  0.86157397  0.87772677\n",
      "  0.86696351  0.87810048  0.86115117  0.87241446  0.87710114  0.90374141\n",
      "  0.87648686  0.88642691  0.86397662  0.8732089   0.89098007  0.88511644\n",
      "  0.86410751  0.86560902  0.85131655  0.87968946  0.87677093  0.8829502\n",
      "  0.87421481  0.88343562  0.86181562  0.8735165   0.85123063  0.84197661\n",
      "  0.84005705  0.87579403  0.88833347  0.85569998  0.8581045   0.85972852\n",
      "  0.873212    0.86652866  0.87087731  0.86796148  0.90819332  0.8838352\n",
      "  0.8943636   0.87413623  0.84276028  0.85844463  0.88431642  0.8867092\n",
      "  0.83608787  0.87496661  0.8664997   0.88307179  0.86181525  0.86446228\n",
      "  0.87161661  0.88202751  0.87850069  0.89782844  0.86791126  0.88514286\n",
      "  0.91288856  0.90664043  0.87345218  0.88265633  0.87806558  0.90991885\n",
      "  0.85881298  0.84411594  0.83988095  0.87185627  0.871574    0.8451776\n",
      "  0.8968439   0.88806062  0.86777463  0.88357459  0.88612265  0.89905286\n",
      "  0.87567936  0.87374107  0.86557223  0.86383418  0.87677786  0.86151363\n",
      "  0.84926892  0.88974101  0.89114469  0.86727862  0.90475347  0.87703185\n",
      "  0.8992162   0.86306109  0.8677487   0.86744821  0.8669083   0.83548764\n",
      "  0.88572378  0.87835006  0.87369234  0.90384438  0.87367786  0.79766317\n",
      "  0.88482882  0.88608793  0.88121284  0.87215627  0.86181589  0.87209384\n",
      "  0.84978798  0.88625183  0.90972892  0.85386955  0.89615128  0.8883246\n",
      "  0.88900092  0.86215064  0.85470265  0.88830342  0.88906539  0.84129042\n",
      "  0.87866529  0.85429475  0.88002004  0.88561384  0.85935026  0.88925172\n",
      "  0.86652755  0.89586357  0.88116333  0.88605609  0.8970023   0.86356022\n",
      "  0.87479864  0.8867454   0.86330887  0.89216947  0.8775165   0.88349426\n",
      "  0.86948698  0.85429534  0.8839903   0.91103458  0.85327006  0.86801213\n",
      "  0.86086445  0.87708387  0.86800531  0.84710289  0.88091101  0.86513971\n",
      "  0.87477974  0.86498263  0.87843339  0.89231169  0.8960086   0.90097934\n",
      "  0.87549784  0.85247167  0.85170834  0.88436978  0.84770746  0.85308425\n",
      "  0.87077312  0.91019838  0.88100178  0.89448006  0.89066771  0.88781883\n",
      "  0.85349823  0.86964526  0.8651403   0.87925941  0.87036909  0.87007199\n",
      "  0.84555825  0.85951156  0.88980615  0.86606131  0.88529617  0.84475083\n",
      "  0.88781514  0.8508942   0.86451668  0.87901526  0.89452274  0.87861032\n",
      "  0.87521962  0.87362383  0.89527412  0.88245296  0.86959185  0.8798045\n",
      "  0.87109822  0.86183009  0.87837487  0.86567102  0.85028112  0.88865275\n",
      "  0.89123236  0.89384879  0.88832273  0.87857435  0.85769332  0.88855696\n",
      "  0.87431232  0.88465191  0.85697207  0.88832086  0.87744401  0.87827303\n",
      "  0.84938652  0.85724489  0.88760369  0.88393742  0.86856973  0.89614027\n",
      "  0.8978548   0.87044619  0.90238591  0.87820013  0.86353347  0.87658601\n",
      "  0.87669562  0.89251911  0.85348625  0.87135401  0.90597872  0.85895512\n",
      "  0.89306109  0.86909063  0.88852803  0.87553979  0.87337905  0.8760551\n",
      "  0.87481424  0.86954153  0.8818863   0.88001791  0.87337577  0.8761434\n",
      "  0.88549867  0.83883399  0.83111791  0.88243168  0.86944855  0.88543994\n",
      "  0.85106338  0.89569351  0.88341852  0.87827163  0.88251264  0.87919282\n",
      "  0.8837541   0.85094416  0.89274002  0.85098665  0.88071403  0.88373034\n",
      "  0.88632761  0.88222019  0.86273648  0.87874601  0.87047774  0.84056117\n",
      "  0.90149689  0.86097426  0.8583356   0.90143069  0.8593005   0.87500701\n",
      "  0.89542869  0.85243957  0.86263217  0.82893999  0.88814453  0.90047267\n",
      "  0.87345049  0.89006165  0.88298862  0.86402342  0.88055893  0.86501364\n",
      "  0.88496725  0.83939877  0.89501199  0.83515662  0.85143647  0.85694702\n",
      "  0.86918682  0.86173229  0.90569087  0.88445514  0.83273773  0.90017595\n",
      "  0.86002845  0.85254945  0.85559164  0.85443848  0.88727744  0.85007119\n",
      "  0.87105116  0.85527209  0.86880779  0.87889009  0.87493209  0.87122114\n",
      "  0.86807622  0.88276118  0.85335278  0.88413429  0.88186916  0.8780313\n",
      "  0.8617972   0.90762861  0.88312137  0.8996029   0.8129957   0.85886573\n",
      "  0.87409788  0.83390621  0.8875725   0.89753844  0.86687254  0.85774776\n",
      "  0.87602096  0.8759304   0.87719085  0.87144333  0.874643    0.8488521\n",
      "  0.85704979  0.89818868  0.87109715  0.87595528  0.88383678  0.89036782\n",
      "  0.87442194  0.88774746  0.89045641  0.86733762  0.8703683   0.87159725\n",
      "  0.8885351   0.89165851  0.87495055  0.89979728  0.90864299  0.86773667\n",
      "  0.8718071   0.87303634  0.86674849  0.87619523  0.85076494  0.89790049\n",
      "  0.86314409  0.86689057  0.84550433  0.87763775  0.8694763   0.86397413\n",
      "  0.86820113  0.86533259  0.85559304  0.86856852  0.85106228  0.89401397\n",
      "  0.90416527  0.88110874  0.89412946  0.86062413  0.86982     0.89709456\n",
      "  0.864438    0.87807492  0.89016309  0.85998607  0.87083207  0.88567125\n",
      "  0.88993099  0.86996693  0.86821774  0.85652983  0.87498022  0.87823221\n",
      "  0.86710764  0.85400037  0.90799964  0.90188026  0.87439099  0.83422645\n",
      "  0.88197886  0.83651084  0.88126585  0.85435727  0.86537749  0.81086606\n",
      "  0.905966    0.87202066  0.84541778  0.88626782  0.89639182  0.86365643\n",
      "  0.863278    0.87835852  0.90905151  0.8736735   0.86421525  0.87683206\n",
      "  0.85803947  0.88876383  0.85920175  0.86681565  0.87286027  0.88837174\n",
      "  0.89538174  0.85161855  0.89851407  0.88695896  0.89938228  0.88953492\n",
      "  0.90196986  0.88027208  0.87597398  0.86571232  0.8823208   0.85656848\n",
      "  0.88142684  0.86740245  0.85594432  0.86733566  0.83536681  0.8896744\n",
      "  0.86790174  0.86798244  0.85606602  0.90506533  0.89288467  0.87408887\n",
      "  0.862791    0.85682482  0.87858003  0.85034028  0.85581193  0.83922047\n",
      "  0.90604655  0.87442244  0.8745905   0.84955136  0.86907033  0.86659395\n",
      "  0.8520321   0.87752722  0.87165605  0.88339853  0.87207489  0.85425764\n",
      "  0.84722369  0.86385701  0.84904294  0.82565452  0.87572675  0.88530994\n",
      "  0.88852808  0.83673358  0.91491877  0.84891844  0.86451992  0.88769576\n",
      "  0.86058254  0.89200891  0.84866481  0.88112081  0.87536213  0.84841506\n",
      "  0.83850284  0.87269987  0.88254493  0.89101208  0.8853559   0.86886866\n",
      "  0.87233412  0.86316056  0.8728306   0.87171589  0.87426518  0.86080621\n",
      "  0.88343776  0.88511744  0.89842467  0.87252837  0.87920293  0.88361656\n",
      "  0.86293029  0.88604195  0.88345099  0.84956059  0.83967944  0.90318017\n",
      "  0.85573105  0.89905141  0.87632544  0.88427017  0.8826596   0.88024651\n",
      "  0.86772178  0.83965432  0.87600876  0.86264532  0.86746923  0.89498793\n",
      "  0.88579292  0.8797812   0.8865803   0.89029186  0.89732632  0.87887463\n",
      "  0.87391609  0.87851778  0.8740003   0.86790091  0.87828688  0.86735399\n",
      "  0.88523071  0.88720304  0.85207444  0.89850794  0.88857749  0.88451794\n",
      "  0.85560587  0.8655064   0.88945854  0.88845905  0.88943689  0.86963674\n",
      "  0.85818967  0.87478011  0.86913195  0.89118202  0.89242661  0.89935255\n",
      "  0.88017396  0.90438367  0.87818908  0.87882196  0.86782323  0.88021931\n",
      "  0.87167314  0.90150331  0.88009909  0.86927621  0.88336299  0.89660612\n",
      "  0.8572257   0.87457708  0.88816574  0.86991015  0.85605003  0.85935536\n",
      "  0.90144879  0.88375309  0.87692338  0.85446572  0.86297721  0.90927096\n",
      "  0.87688649  0.87436103  0.89271357  0.84990811  0.88516502  0.86952102\n",
      "  0.89079814  0.90316596  0.88253215  0.86496834  0.87062414  0.86477191\n",
      "  0.86626049  0.87785726  0.90922092  0.84267236  0.83685861  0.88222385\n",
      "  0.85683527  0.8671479   0.88548548  0.886205    0.89715228  0.86861228\n",
      "  0.84977673  0.85228681  0.90056522  0.8740244   0.85541809  0.85502324\n",
      "  0.88872958  0.88304822  0.88064016  0.87299063  0.8709963   0.87388076\n",
      "  0.85918195  0.89557709  0.86346597  0.88029628  0.86914155  0.88695456\n",
      "  0.87201089  0.87188544  0.88051486  0.90250398  0.86101989  0.88502211\n",
      "  0.85753998  0.88096484  0.8900292   0.88273138  0.88520654  0.8796904\n",
      "  0.88593914  0.8845245   0.86713899  0.85157736  0.86941409  0.88875454\n",
      "  0.84902527  0.89617913  0.89724441  0.84429601  0.90901099  0.86536631\n",
      "  0.87703394  0.86074364  0.86641345  0.87738441  0.88842978  0.88163358\n",
      "  0.91426248  0.90095761  0.87181055  0.86078814  0.87503683  0.864839\n",
      "  0.88577863  0.86647676  0.85925872  0.86675442  0.83970166  0.87498849\n",
      "  0.8481972   0.88703847  0.87594394  0.88128437  0.85743155  0.89622456\n",
      "  0.85270142  0.88098557  0.83703112  0.88018955  0.86390786  0.86841676\n",
      "  0.87565416  0.87594672  0.86179756  0.88444684  0.89544542  0.90817879\n",
      "  0.84698019  0.89326323  0.87228225  0.88625214  0.88594588  0.90149738\n",
      "  0.86714879  0.87515246  0.87251596  0.87960313  0.8563214   0.87254152\n",
      "  0.88361287  0.84923415  0.88504695  0.84752245  0.8677482   0.86520686\n",
      "  0.85917109  0.89164537  0.85812159  0.88651908  0.85740652  0.88353192\n",
      "  0.84539153  0.84667855  0.89781566  0.86708265  0.88736616  0.88395601\n",
      "  0.8950261   0.84952733  0.88118058  0.8681965   0.88911623  0.86766084\n",
      "  0.86705005  0.88339935  0.85911646  0.85639442  0.85043811  0.82796184\n",
      "  0.85425316  0.8858986   0.8860523   0.89429879  0.88681312  0.87471905\n",
      "  0.84384926  0.88927837  0.90252705  0.90116379  0.8586929   0.86500954\n",
      "  0.88707005  0.8989543   0.84972919  0.89150223  0.89255433  0.8846074\n",
      "  0.89247341  0.88746418  0.86780165  0.87919395  0.89426214  0.85383331\n",
      "  0.84460777  0.90872979  0.8607559   0.85901006  0.87395188  0.85861124\n",
      "  0.88395019  0.8734719   0.8663726   0.87718197  0.85356584  0.88362499\n",
      "  0.87880739  0.85359272  0.86880287  0.85457255  0.87340451  0.85904502\n",
      "  0.86964982  0.8692682   0.88813981  0.88993557  0.87686773  0.88611891\n",
      "  0.86584293  0.88683276  0.86765429  0.85917071  0.87486534  0.8734487\n",
      "  0.84936422  0.88474258  0.86752671  0.87304     0.87562142  0.88381895\n",
      "  0.87529605  0.86797822  0.87992209  0.87952571  0.86502094  0.85016452\n",
      "  0.87095833  0.86425621  0.85861178  0.86869168  0.87208707  0.86711751\n",
      "  0.87819214  0.87526135  0.85603605  0.89932863  0.8781173   0.88006757\n",
      "  0.88883651  0.86968214  0.88215342  0.89762856  0.87488054  0.85809383\n",
      "  0.83769315  0.87452245  0.8688331   0.86098273  0.86314649  0.87860855\n",
      "  0.87257437  0.837223    0.84416805  0.86626633  0.89282307  0.86745857\n",
      "  0.8812595   0.87895939  0.86353105  0.87770822  0.85431905  0.92590656\n",
      "  0.86531493  0.89401378  0.856916    0.86319756  0.89882289  0.89452431\n",
      "  0.86605453  0.87038329  0.88056456  0.8776969   0.86384933  0.87892261\n",
      "  0.87930992  0.87589739  0.87415536  0.85321449  0.87470116  0.89126205\n",
      "  0.88650476  0.84661644  0.9012546   0.86622175  0.86414888  0.86830503\n",
      "  0.85507194  0.88057508  0.86714902  0.86865614  0.88701018  0.87497856\n",
      "  0.86711294  0.86197631  0.88022159  0.869442    0.87764016  0.87428661\n",
      "  0.84413049  0.87882941  0.85124321  0.87749148  0.85707794  0.85472464\n",
      "  0.87140198  0.87389081  0.87955792  0.87678853  0.89271081  0.86983647\n",
      "  0.87309278  0.89260927  0.88400617  0.88207431  0.88410375  0.8455056\n",
      "  0.89344867  0.89238166  0.87511267  0.87775324  0.85196488  0.85671702\n",
      "  0.87560961  0.85331662  0.89051642  0.8997919   0.88591151  0.85841695\n",
      "  0.85893637  0.86752546  0.88701321  0.87108056  0.8771561   0.88679417\n",
      "  0.88637569  0.86820691  0.85174382  0.88237321  0.88556105  0.87909819\n",
      "  0.87395885  0.87533891  0.86762658  0.85764221  0.88289769  0.8722278\n",
      "  0.86777009  0.869615    0.8847333   0.8780496   0.8833813   0.88687063\n",
      "  0.87919428  0.81659982  0.85876618  0.82972656  0.82932369  0.8570546\n",
      "  0.85289867  0.87821306  0.87824765  0.87423398  0.84638453  0.87290221\n",
      "  0.87470668  0.87212763  0.86026052  0.87795551  0.87924994  0.89013607\n",
      "  0.86383565  0.90786544  0.87729606  0.87042133  0.88931302  0.87895617\n",
      "  0.87041946  0.86435291  0.88103082  0.86794893]\n"
     ]
    }
   ],
   "source": [
    "print(repeat_1000('gbr'))\n",
    "##pick one name a time from {\"gbr\",\"rf\",\"adrf\",\"bq\",\"svr\",\"lasso\",\"krr\",\"hr\",\"ridge\"}\n",
    "##print correlation coefficients from 1000 repeated runs, based on which we can compute mean value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
